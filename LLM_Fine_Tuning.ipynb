{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "!pip install -U autotrain-advanced > install_logs.txt\n",
        "!autotrain setup --colab > setup_logs.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SrUJx528GTN",
        "outputId": "ae7bebe5-cdd8-460d-99dd-3b89e69f5626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchvision==0.15.2\n",
            "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (2.31.0)\n",
            "Collecting torch==2.0.1 (from torchvision==0.15.2)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (10.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision==0.15.2) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.1->torchvision==0.15.2)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision==0.15.2) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision==0.15.2) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision==0.15.2) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1->torchvision==0.15.2)\n",
            "  Downloading lit-18.1.6-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision==0.15.2) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision==0.15.2) (1.3.0)\n",
            "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.0\n",
            "    Uninstalling torch-2.2.0:\n",
            "      Successfully uninstalled torch-2.2.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.18.0+cu121\n",
            "    Uninstalling torchvision-0.18.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.18.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.0.1 which is incompatible.\n",
            "xformers 0.0.24 requires torch==2.2.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 torchvision-0.15.2 triton-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ваш код для подготовки данных и запуска autotrain\n",
        "os.environ['MODEL_NAME'] = 'IlyaGusev/saiga_mistral_7b_merged'\n",
        "os.environ['PROJECT_NAME'] = 'mistral-7b-mj-finetuned'\n",
        "os.environ['LEARNING_RATE'] = '2e-4'\n",
        "os.environ['BATCH_SIZE'] = '4'  # Уменьшение размера батча\n",
        "os.environ['NUM_EPOCHS'] = '3'\n",
        "os.environ['BLOCK_SIZE'] = '512'\n",
        "os.environ['WARMUP_RATIO'] = '0.1'\n",
        "os.environ['LORA_R'] = '8'\n",
        "os.environ['LORA_ALPHA'] = '32'\n",
        "os.environ['LORA_DROPOUT'] = '0.1'\n",
        "os.environ['WEIGHT_DECAY'] = '0.01'\n",
        "os.environ['GRADIENT_ACCUMULATION'] = '8'  # Увеличение градиентного накопления\n",
        "os.environ['QUANTIZATION'] = 'int4'\n",
        "os.environ['MIXED_PRECISION'] = 'fp16'\n",
        "os.environ['HF_USERNAME'] = 'ValterVar1'\n",
        "os.environ['TRAINER'] = 'sft'\n",
        "os.environ['PEFT'] = 'True'\n",
        "os.environ['PUSH_TO_HUB'] = 'True'\n",
        "os.environ['HF_TOKEN'] = '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'"
      ],
      "metadata": {
        "id": "3bHOAZsW8GM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!autotrain llm \\\n",
        "--train \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--data-path data/ \\\n",
        "--text-column text \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--epochs ${NUM_EPOCHS} \\\n",
        "--block-size ${BLOCK_SIZE} \\\n",
        "--warmup-ratio ${WARMUP_RATIO} \\\n",
        "--lora-r ${LORA_R} \\\n",
        "--lora-alpha ${LORA_ALPHA} \\\n",
        "--lora-dropout ${LORA_DROPOUT} \\\n",
        "--weight-decay ${WEIGHT_DECAY} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--quantization ${QUANTIZATION} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "--trainer ${TRAINER} \\\n",
        "$( [[ \"$PEFT\" == \"True\" ]] && echo \"--peft\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )"
      ],
      "metadata": {
        "id": "hCp_UC7K8GK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ddf331a-f103-4419-cc50-697159a47abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 21:42:51\u001b[0m | \u001b[36mautotrain.cli.run_llm\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m344\u001b[0m - \u001b[1mRunning LLM\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-21 21:42:52\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: version, backend, inference, train, func, config, deploy\u001b[0m\n",
            "\rSaving the dataset (0/1 shards):   0% 0/794 [00:00<?, ? examples/s]\rSaving the dataset (1/1 shards): 100% 794/794 [00:00<00:00, 99864.38 examples/s]\rSaving the dataset (1/1 shards): 100% 794/794 [00:00<00:00, 97149.28 examples/s]\n",
            "\rSaving the dataset (0/1 shards):   0% 0/794 [00:00<?, ? examples/s]\rSaving the dataset (1/1 shards): 100% 794/794 [00:00<00:00, 99882.35 examples/s]\rSaving the dataset (1/1 shards): 100% 794/794 [00:00<00:00, 97765.31 examples/s]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 21:42:52\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 21:42:52\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m360\u001b[0m - \u001b[1m['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'fp16', '-m', 'autotrain.trainers.clm', '--training_config', 'mistral-7b-mj-finetuned/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 21:42:52\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1m{'model': 'IlyaGusev/saiga_mistral_7b_merged', 'project_name': 'mistral-7b-mj-finetuned', 'data_path': 'mistral-7b-mj-finetuned/autotrain-data', 'train_split': 'train', 'valid_split': None, 'add_eos_token': False, 'block_size': 512, 'model_max_length': 1024, 'padding': None, 'trainer': 'sft', 'use_flash_attention_2': False, 'log': 'none', 'disable_gradient_checkpointing': False, 'logging_steps': -1, 'evaluation_strategy': 'epoch', 'save_total_limit': 1, 'auto_find_batch_size': False, 'mixed_precision': 'fp16', 'lr': 0.0002, 'epochs': 3, 'batch_size': 4, 'warmup_ratio': 0.1, 'gradient_accumulation': 8, 'optimizer': 'adamw_torch', 'scheduler': 'linear', 'weight_decay': 0.01, 'max_grad_norm': 1.0, 'seed': 42, 'chat_template': None, 'quantization': 'int4', 'target_modules': 'all-linear', 'merge_adapter': False, 'peft': True, 'lora_r': 8, 'lora_alpha': 32, 'lora_dropout': 0.1, 'model_ref': None, 'dpo_beta': 0.1, 'max_prompt_length': 128, 'max_completion_length': None, 'prompt_text_column': 'autotrain_prompt', 'text_column': 'autotrain_text', 'rejected_text_column': 'autotrain_rejected_text', 'push_to_hub': True, 'username': 'ValterVar1', 'token': '*****'}\u001b[0m\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 21:43:02\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m14\u001b[0m - \u001b[1mStarting SFT training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 21:43:02\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mloading dataset from disk\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 21:43:02\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m388\u001b[0m - \u001b[1mTrain data: Dataset({\n",
            "    features: ['id', 'vac_name', 'desc', 'values', 'autotrain_text'],\n",
            "    num_rows: 794\n",
            "})\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 21:43:02\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m389\u001b[0m - \u001b[1mValid data: None\u001b[0m\n",
            "tokenizer_config.json: 100% 1.35k/1.35k [00:00<00:00, 7.45MB/s]\n",
            "tokenizer.model: 100% 493k/493k [00:00<00:00, 8.30MB/s]\n",
            "tokenizer.json: 100% 1.80M/1.80M [00:00<00:00, 62.9MB/s]\n",
            "added_tokens.json: 100% 90.0/90.0 [00:00<00:00, 461kB/s]\n",
            "special_tokens_map.json: 100% 169/169 [00:00<00:00, 1.16MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 21:43:03\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_logging_steps\u001b[0m:\u001b[36m461\u001b[0m - \u001b[1mconfiguring logging steps\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 21:43:03\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_logging_steps\u001b[0m:\u001b[36m474\u001b[0m - \u001b[1mLogging steps: 25\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 21:43:03\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_training_args\u001b[0m:\u001b[36m479\u001b[0m - \u001b[1mconfiguring training args\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 21:43:03\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_block_size\u001b[0m:\u001b[36m542\u001b[0m - \u001b[1mUsing block size 512\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 21:43:03\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m27\u001b[0m - \u001b[1mloading model config...\u001b[0m\n",
            "config.json: 100% 622/622 [00:00<00:00, 3.62MB/s]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 21:43:03\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1mloading model...\u001b[0m\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "pytorch_model.bin.index.json: 100% 23.9k/23.9k [00:00<00:00, 53.4MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00002.bin:   0% 0.00/9.94G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   0% 10.5M/9.94G [00:00<04:22, 37.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   0% 21.0M/9.94G [00:00<02:55, 56.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   0% 41.9M/9.94G [00:00<01:41, 97.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 73.4M/9.94G [00:00<01:10, 139MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 105M/9.94G [00:00<00:58, 169MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 126M/9.94G [00:00<00:54, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 147M/9.94G [00:01<00:53, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 168M/9.94G [00:01<00:51, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 189M/9.94G [00:01<00:50, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 210M/9.94G [00:01<00:50, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 231M/9.94G [00:01<00:50, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 252M/9.94G [00:01<00:49, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 273M/9.94G [00:01<00:48, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 294M/9.94G [00:01<00:47, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 315M/9.94G [00:01<00:48, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 346M/9.94G [00:02<00:46, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 377M/9.94G [00:02<00:44, 213MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 409M/9.94G [00:02<00:45, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 430M/9.94G [00:02<00:46, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 451M/9.94G [00:02<00:47, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 472M/9.94G [00:02<00:47, 200MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 493M/9.94G [00:02<00:47, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 514M/9.94G [00:04<05:18, 29.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 545M/9.94G [00:05<03:32, 44.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 577M/9.94G [00:05<02:32, 61.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 608M/9.94G [00:05<01:55, 81.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 629M/9.94G [00:05<01:38, 94.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 650M/9.94G [00:05<01:28, 105MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 671M/9.94G [00:05<01:17, 119MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 692M/9.94G [00:05<01:09, 134MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 713M/9.94G [00:05<01:03, 145MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 734M/9.94G [00:06<00:58, 157MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 755M/9.94G [00:06<00:54, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 786M/9.94G [00:06<00:49, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 807M/9.94G [00:06<00:48, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 839M/9.94G [00:06<00:45, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 870M/9.94G [00:06<00:44, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 902M/9.94G [00:06<00:42, 211MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 933M/9.94G [00:07<00:45, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 954M/9.94G [00:07<00:45, 198MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 975M/9.94G [00:07<00:45, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 996M/9.94G [00:07<00:45, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.02G/9.94G [00:07<00:45, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.04G/9.94G [00:11<07:44, 19.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.06G/9.94G [00:11<05:43, 25.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.09G/9.94G [00:11<03:47, 38.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.12G/9.94G [00:11<02:45, 53.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.14G/9.94G [00:11<02:36, 56.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.16G/9.94G [00:12<02:17, 64.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.18G/9.94G [00:12<02:15, 64.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.21G/9.94G [00:12<02:00, 72.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.23G/9.94G [00:12<01:41, 86.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.25G/9.94G [00:12<01:44, 83.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.27G/9.94G [00:13<01:42, 84.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.30G/9.94G [00:13<01:19, 109MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.32G/9.94G [00:13<01:18, 109MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.34G/9.94G [00:13<01:10, 123MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.36G/9.94G [00:13<01:12, 119MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.38G/9.94G [00:14<01:15, 113MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.42G/9.94G [00:14<01:02, 137MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.44G/9.94G [00:14<01:20, 106MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.46G/9.94G [00:14<01:10, 120MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.48G/9.94G [00:14<01:02, 136MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.50G/9.94G [00:14<00:58, 145MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.52G/9.94G [00:14<00:56, 150MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.54G/9.94G [00:15<00:53, 156MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.56G/9.94G [00:15<00:53, 158MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.58G/9.94G [00:15<00:51, 161MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.60G/9.94G [00:15<00:48, 172MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.63G/9.94G [00:15<00:46, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.65G/9.94G [00:15<00:46, 180MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.67G/9.94G [00:15<00:45, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.69G/9.94G [00:16<01:08, 120MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.71G/9.94G [00:16<01:02, 132MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.73G/9.94G [00:16<00:58, 140MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.75G/9.94G [00:16<00:56, 146MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.77G/9.94G [00:16<00:53, 152MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.79G/9.94G [00:16<00:52, 155MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.81G/9.94G [00:16<00:49, 164MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.84G/9.94G [00:16<00:47, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.86G/9.94G [00:17<00:46, 175MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.88G/9.94G [00:17<00:45, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.90G/9.94G [00:17<00:44, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.92G/9.94G [00:17<00:47, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.94G/9.94G [00:17<00:49, 161MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.96G/9.94G [00:17<00:49, 162MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.98G/9.94G [00:17<00:48, 165MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.00G/9.94G [00:17<00:49, 161MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.02G/9.94G [00:20<06:09, 21.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.04G/9.94G [00:21<05:06, 25.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.08G/9.94G [00:21<03:19, 39.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.11G/9.94G [00:21<02:19, 56.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.14G/9.94G [00:21<01:45, 74.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.16G/9.94G [00:21<01:31, 85.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.18G/9.94G [00:22<01:17, 100MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.20G/9.94G [00:22<01:07, 115MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.22G/9.94G [00:22<00:59, 130MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.24G/9.94G [00:22<00:52, 146MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.26G/9.94G [00:22<00:48, 158MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.30G/9.94G [00:22<00:43, 175MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.33G/9.94G [00:22<00:40, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.36G/9.94G [00:22<00:38, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.39G/9.94G [00:23<00:39, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.41G/9.94G [00:23<00:40, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.43G/9.94G [00:23<00:40, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.45G/9.94G [00:23<00:40, 187MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.47G/9.94G [00:23<00:39, 188MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.50G/9.94G [00:24<01:56, 64.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.52G/9.94G [00:24<01:40, 74.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.54G/9.94G [00:24<01:45, 70.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.56G/9.94G [00:25<01:25, 85.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.58G/9.94G [00:25<01:17, 94.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.60G/9.94G [00:25<01:16, 95.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.62G/9.94G [00:25<01:04, 113MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.64G/9.94G [00:25<01:02, 117MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.66G/9.94G [00:25<00:54, 135MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.68G/9.94G [00:26<01:13, 98.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.71G/9.94G [00:26<01:03, 115MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.73G/9.94G [00:26<00:54, 132MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.75G/9.94G [00:26<00:52, 137MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.77G/9.94G [00:26<00:48, 148MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.79G/9.94G [00:26<00:54, 130MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.81G/9.94G [00:26<00:49, 143MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.84G/9.94G [00:27<00:51, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.86G/9.94G [00:27<00:55, 129MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.88G/9.94G [00:27<00:50, 141MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.90G/9.94G [00:27<00:45, 154MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.93G/9.94G [00:27<00:42, 165MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.95G/9.94G [00:27<00:41, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.97G/9.94G [00:27<00:40, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.99G/9.94G [00:29<03:55, 29.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.01G/9.94G [00:30<02:55, 39.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.03G/9.94G [00:30<02:13, 51.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.05G/9.94G [00:30<01:44, 66.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.07G/9.94G [00:30<01:23, 82.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.09G/9.94G [00:30<01:09, 98.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.11G/9.94G [00:30<01:00, 112MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.14G/9.94G [00:30<00:53, 127MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.16G/9.94G [00:30<00:49, 138MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.18G/9.94G [00:31<00:45, 148MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.20G/9.94G [00:31<00:42, 159MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.22G/9.94G [00:31<00:39, 168MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.24G/9.94G [00:31<00:38, 173MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.27G/9.94G [00:31<00:35, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.30G/9.94G [00:31<00:32, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.32G/9.94G [00:31<00:32, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.36G/9.94G [00:31<00:31, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.38G/9.94G [00:32<00:33, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.40G/9.94G [00:32<00:34, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.42G/9.94G [00:32<00:34, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.44G/9.94G [00:32<00:33, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.46G/9.94G [00:35<05:10, 20.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.48G/9.94G [00:35<03:50, 28.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.51G/9.94G [00:35<02:32, 42.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.54G/9.94G [00:35<01:48, 59.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.58G/9.94G [00:36<01:21, 78.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.60G/9.94G [00:36<01:24, 74.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.62G/9.94G [00:36<01:11, 88.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.64G/9.94G [00:36<01:01, 102MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.66G/9.94G [00:36<00:54, 116MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.68G/9.94G [00:36<00:48, 129MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.71G/9.94G [00:37<00:41, 151MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.73G/9.94G [00:37<00:38, 162MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.76G/9.94G [00:37<00:34, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.80G/9.94G [00:37<00:32, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.83G/9.94G [00:37<00:30, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.86G/9.94G [00:37<00:30, 200MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.88G/9.94G [00:37<00:31, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.90G/9.94G [00:37<00:31, 194MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.92G/9.94G [00:38<00:31, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.94G/9.94G [00:38<00:31, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.96G/9.94G [00:38<00:36, 166MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.98G/9.94G [00:41<05:08, 19.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.01G/9.94G [00:42<03:59, 24.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.03G/9.94G [00:42<03:14, 30.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.04G/9.94G [00:42<02:51, 34.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.05G/9.94G [00:42<02:33, 38.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.06G/9.94G [00:42<02:21, 41.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.07G/9.94G [00:42<02:04, 47.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.09G/9.94G [00:43<01:30, 64.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.11G/9.94G [00:43<01:10, 82.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.14G/9.94G [00:43<00:50, 114MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.17G/9.94G [00:43<00:41, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.20G/9.94G [00:43<00:35, 160MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.23G/9.94G [00:43<00:34, 166MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.25G/9.94G [00:43<00:33, 171MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.27G/9.94G [00:44<00:33, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.29G/9.94G [00:44<00:33, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.31G/9.94G [00:44<00:32, 172MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.33G/9.94G [00:44<00:31, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.35G/9.94G [00:44<00:30, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.37G/9.94G [00:44<00:29, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.39G/9.94G [00:44<00:29, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.42G/9.94G [00:44<00:27, 200MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.46G/9.94G [00:45<00:26, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.49G/9.94G [00:45<00:26, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.52G/9.94G [00:46<01:45, 51.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.54G/9.94G [00:46<01:29, 60.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.56G/9.94G [00:46<01:13, 72.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.58G/9.94G [00:47<01:01, 87.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.60G/9.94G [00:47<01:06, 80.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.63G/9.94G [00:47<00:50, 106MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.67G/9.94G [00:47<00:41, 127MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.69G/9.94G [00:47<00:37, 141MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.71G/9.94G [00:47<00:34, 150MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.73G/9.94G [00:48<00:33, 158MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.75G/9.94G [00:48<00:31, 163MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.77G/9.94G [00:48<00:30, 168MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.79G/9.94G [00:48<00:29, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.81G/9.94G [00:48<00:35, 144MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.83G/9.94G [00:52<04:36, 18.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.87G/9.94G [00:52<02:56, 28.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.90G/9.94G [00:52<02:01, 41.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.92G/9.94G [00:52<01:36, 52.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.94G/9.94G [00:52<01:17, 64.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.96G/9.94G [00:52<01:03, 78.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.98G/9.94G [00:52<00:54, 90.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.00G/9.94G [00:52<00:48, 102MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.02G/9.94G [00:53<00:42, 117MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.04G/9.94G [00:53<00:37, 130MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.06G/9.94G [00:53<00:37, 131MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.09G/9.94G [00:53<00:33, 144MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.11G/9.94G [00:53<00:32, 148MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.13G/9.94G [00:53<00:43, 110MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.15G/9.94G [00:54<00:41, 115MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.17G/9.94G [00:54<00:52, 90.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.19G/9.94G [00:54<00:49, 95.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.21G/9.94G [00:54<00:46, 102MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.23G/9.94G [00:55<01:38, 47.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.26G/9.94G [00:56<01:13, 63.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.30G/9.94G [00:56<00:59, 78.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.32G/9.94G [00:56<00:57, 80.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.34G/9.94G [00:56<00:50, 90.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.36G/9.94G [00:56<00:43, 106MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.38G/9.94G [00:56<00:38, 118MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.41G/9.94G [00:57<00:32, 141MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.44G/9.94G [00:57<00:28, 161MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.47G/9.94G [00:57<00:25, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.49G/9.94G [00:57<00:25, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.52G/9.94G [00:57<00:24, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.54G/9.94G [00:57<00:24, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.57G/9.94G [00:57<00:22, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.59G/9.94G [00:57<00:22, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.62G/9.94G [00:58<00:21, 201MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.65G/9.94G [00:58<00:20, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.68G/9.94G [00:58<00:20, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.70G/9.94G [00:58<00:20, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.73G/9.94G [00:58<00:20, 201MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.76G/9.94G [00:58<00:20, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.78G/9.94G [01:00<01:21, 51.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.80G/9.94G [01:00<01:06, 62.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.82G/9.94G [01:00<00:58, 70.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.84G/9.94G [01:00<00:48, 85.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.86G/9.94G [01:00<00:40, 101MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.88G/9.94G [01:00<00:35, 115MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.90G/9.94G [01:00<00:31, 129MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.92G/9.94G [01:00<00:27, 144MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.95G/9.94G [01:01<00:25, 157MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.97G/9.94G [01:01<00:24, 164MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.99G/9.94G [01:01<00:23, 169MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.01G/9.94G [01:01<00:22, 172MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.03G/9.94G [01:01<00:21, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.05G/9.94G [01:01<00:21, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.07G/9.94G [01:01<00:21, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.09G/9.94G [01:01<00:20, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.11G/9.94G [01:01<00:20, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.13G/9.94G [01:02<00:20, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.16G/9.94G [01:02<00:20, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.18G/9.94G [01:02<00:20, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.21G/9.94G [01:02<00:19, 195MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.24G/9.94G [01:02<00:18, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.27G/9.94G [01:02<00:17, 210MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.30G/9.94G [01:02<00:17, 212MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.33G/9.94G [01:03<00:17, 207MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.35G/9.94G [01:03<00:17, 202MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.39G/9.94G [01:03<00:17, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.41G/9.94G [01:03<00:17, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.43G/9.94G [01:03<00:17, 200MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.45G/9.94G [01:03<00:17, 200MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.47G/9.94G [01:03<00:17, 200MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.50G/9.94G [01:03<00:16, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.52G/9.94G [01:06<02:10, 26.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.54G/9.94G [01:06<01:40, 33.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.56G/9.94G [01:06<01:22, 41.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.59G/9.94G [01:07<01:09, 48.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.61G/9.94G [01:07<01:06, 49.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.62G/9.94G [01:07<01:00, 54.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.64G/9.94G [01:07<00:47, 70.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.66G/9.94G [01:07<00:38, 85.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.68G/9.94G [01:08<00:33, 97.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.70G/9.94G [01:08<00:39, 82.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.72G/9.94G [01:08<00:39, 82.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.73G/9.94G [01:08<00:37, 85.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.74G/9.94G [01:08<00:37, 84.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.75G/9.94G [01:09<00:38, 82.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.77G/9.94G [01:09<00:37, 85.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.78G/9.94G [01:09<00:37, 83.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.81G/9.94G [01:09<00:29, 105MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.83G/9.94G [01:09<00:30, 102MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.85G/9.94G [01:09<00:28, 107MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.87G/9.94G [01:10<00:27, 111MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.89G/9.94G [01:10<00:24, 125MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.91G/9.94G [01:10<00:21, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.93G/9.94G [01:10<00:21, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.96G/9.94G [01:10<00:22, 131MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.98G/9.94G [01:11<00:50, 59.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.00G/9.94G [01:11<00:42, 69.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.03G/9.94G [01:11<00:36, 79.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.05G/9.94G [01:12<00:33, 85.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.07G/9.94G [01:12<00:30, 94.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.09G/9.94G [01:12<00:25, 110MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.11G/9.94G [01:12<00:22, 127MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.13G/9.94G [01:12<00:20, 139MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.16G/9.94G [01:12<00:17, 163MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.19G/9.94G [01:12<00:15, 176MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.21G/9.94G [01:13<00:15, 179MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.25G/9.94G [01:13<00:14, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.28G/9.94G [01:13<00:13, 200MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.31G/9.94G [01:13<00:12, 209MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.34G/9.94G [01:13<00:12, 204MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.36G/9.94G [01:13<00:12, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.38G/9.94G [01:13<00:12, 200MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.41G/9.94G [01:14<00:12, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.43G/9.94G [01:18<02:33, 16.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.46G/9.94G [01:18<01:55, 21.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.48G/9.94G [01:19<01:26, 28.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.50G/9.94G [01:19<01:05, 37.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.52G/9.94G [01:19<00:50, 48.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.54G/9.94G [01:19<00:39, 60.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.56G/9.94G [01:19<00:33, 72.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.58G/9.94G [01:19<00:28, 83.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.60G/9.94G [01:19<00:25, 92.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.62G/9.94G [01:20<00:21, 108MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.64G/9.94G [01:20<00:18, 123MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.67G/9.94G [01:20<00:16, 137MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.69G/9.94G [01:20<00:15, 149MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.71G/9.94G [01:20<00:16, 133MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.73G/9.94G [01:20<00:14, 148MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.76G/9.94G [01:20<00:13, 168MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.78G/9.94G [01:20<00:12, 174MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.80G/9.94G [01:21<00:12, 175MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.83G/9.94G [01:21<00:11, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.85G/9.94G [01:21<00:11, 182MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.87G/9.94G [01:24<01:42, 20.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.91G/9.94G [01:24<01:07, 30.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.94G/9.94G [01:25<00:46, 43.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.97G/9.94G [01:25<00:33, 59.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.99G/9.94G [01:25<00:27, 71.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.01G/9.94G [01:25<00:23, 83.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.03G/9.94G [01:25<00:19, 97.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.05G/9.94G [01:25<00:16, 112MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.08G/9.94G [01:25<00:13, 138MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.11G/9.94G [01:25<00:12, 150MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.14G/9.94G [01:26<00:10, 168MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.16G/9.94G [01:26<00:10, 171MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.18G/9.94G [01:26<00:10, 175MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.21G/9.94G [01:26<00:09, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.23G/9.94G [01:26<00:11, 147MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.25G/9.94G [01:30<01:41, 16.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.27G/9.94G [01:31<01:15, 22.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.29G/9.94G [01:31<00:56, 29.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.33G/9.94G [01:31<00:37, 43.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.35G/9.94G [01:31<00:29, 54.8MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.37G/9.94G [01:31<00:23, 65.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.39G/9.94G [01:31<00:19, 78.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.41G/9.94G [01:31<00:17, 89.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.43G/9.94G [01:32<00:14, 107MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.45G/9.94G [01:32<00:11, 124MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.47G/9.94G [01:32<00:10, 135MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.49G/9.94G [01:32<00:10, 141MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.51G/9.94G [01:32<00:09, 144MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.54G/9.94G [01:32<00:09, 152MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.56G/9.94G [01:32<00:08, 161MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.58G/9.94G [01:36<01:09, 19.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.60G/9.94G [01:37<01:12, 18.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.63G/9.94G [01:37<00:45, 28.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.66G/9.94G [01:37<00:30, 42.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.69G/9.94G [01:37<00:21, 57.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.71G/9.94G [01:37<00:17, 68.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.73G/9.94G [01:38<00:14, 81.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.76G/9.94G [01:38<00:12, 96.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.78G/9.94G [01:38<00:10, 112MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.80G/9.94G [01:38<00:08, 129MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.82G/9.94G [01:38<00:07, 145MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.85G/9.94G [01:38<00:06, 164MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.88G/9.94G [01:38<00:05, 181MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.90G/9.94G [01:38<00:05, 185MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.93G/9.94G [01:38<00:05, 196MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.97G/9.94G [01:39<00:04, 197MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.99G/9.94G [01:39<00:04, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.01G/9.94G [01:39<00:04, 189MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.03G/9.94G [01:39<00:05, 170MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.05G/9.94G [01:39<00:09, 97.0MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.07G/9.94G [01:43<00:45, 19.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.09G/9.94G [01:43<00:33, 25.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.11G/9.94G [01:43<00:24, 34.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.13G/9.94G [01:43<00:17, 45.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.15G/9.94G [01:43<00:13, 58.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.18G/9.94G [01:43<00:10, 71.5MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.20G/9.94G [01:44<00:08, 84.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.22G/9.94G [01:44<00:07, 98.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.24G/9.94G [01:44<00:06, 115MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.26G/9.94G [01:44<00:05, 131MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.28G/9.94G [01:44<00:04, 145MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.30G/9.94G [01:44<00:04, 157MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.32G/9.94G [01:44<00:03, 159MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.34G/9.94G [01:44<00:03, 151MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.36G/9.94G [01:45<00:03, 152MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.38G/9.94G [01:45<00:03, 154MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.41G/9.94G [01:45<00:03, 166MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.43G/9.94G [01:45<00:02, 173MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.45G/9.94G [01:45<00:02, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.47G/9.94G [01:45<00:02, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.49G/9.94G [01:45<00:02, 166MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.51G/9.94G [01:45<00:02, 164MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.53G/9.94G [01:45<00:02, 167MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.55G/9.94G [01:46<00:02, 136MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.57G/9.94G [01:49<00:19, 18.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.60G/9.94G [01:49<00:11, 29.1MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.64G/9.94G [01:49<00:07, 42.3MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.67G/9.94G [01:50<00:04, 58.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.69G/9.94G [01:50<00:03, 70.6MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.71G/9.94G [01:50<00:02, 79.4MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.73G/9.94G [01:50<00:02, 89.2MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.75G/9.94G [01:50<00:02, 89.9MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.77G/9.94G [01:50<00:01, 92.7MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.80G/9.94G [01:51<00:01, 118MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.84G/9.94G [01:51<00:00, 142MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.87G/9.94G [01:51<00:00, 161MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.89G/9.94G [01:51<00:00, 166MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.91G/9.94G [01:51<00:00, 172MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.94G/9.94G [01:52<00:00, 88.5MB/s]\n",
            "Downloading shards:  50% 1/2 [01:52<01:52, 112.40s/it]\n",
            "pytorch_model-00002-of-00002.bin:   0% 0.00/4.54G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   0% 10.5M/4.54G [00:00<00:50, 90.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   0% 21.0M/4.54G [00:00<02:24, 31.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   1% 31.5M/4.54G [00:03<09:34, 7.85MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   1% 52.4M/4.54G [00:03<04:21, 17.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   2% 83.9M/4.54G [00:03<02:08, 34.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   3% 115M/4.54G [00:03<01:20, 55.2MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   3% 136M/4.54G [00:03<01:02, 70.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   3% 157M/4.54G [00:03<00:50, 86.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   4% 178M/4.54G [00:03<00:42, 103MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   4% 199M/4.54G [00:03<00:36, 119MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   5% 220M/4.54G [00:04<00:32, 134MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   6% 252M/4.54G [00:04<00:27, 156MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   6% 283M/4.54G [00:04<00:24, 173MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   7% 304M/4.54G [00:04<00:24, 176MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   7% 325M/4.54G [00:04<00:23, 180MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   8% 346M/4.54G [00:04<00:23, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   8% 367M/4.54G [00:04<00:24, 174MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   9% 388M/4.54G [00:04<00:25, 163MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   9% 409M/4.54G [00:05<00:25, 160MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   9% 430M/4.54G [00:05<00:24, 167MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  10% 451M/4.54G [00:05<00:35, 116MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  10% 472M/4.54G [00:09<03:59, 17.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  11% 503M/4.54G [00:09<02:32, 26.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  12% 535M/4.54G [00:09<01:43, 38.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  12% 566M/4.54G [00:09<01:13, 53.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  13% 587M/4.54G [00:09<01:01, 64.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  13% 608M/4.54G [00:09<00:50, 77.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  14% 629M/4.54G [00:10<00:41, 93.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  14% 650M/4.54G [00:10<00:35, 109MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  15% 671M/4.54G [00:10<00:39, 97.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  15% 692M/4.54G [00:10<00:49, 77.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  16% 713M/4.54G [00:10<00:40, 94.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  16% 744M/4.54G [00:11<00:34, 110MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  17% 765M/4.54G [00:11<00:31, 120MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  17% 786M/4.54G [00:11<00:29, 129MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  18% 807M/4.54G [00:11<00:26, 141MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  18% 828M/4.54G [00:11<00:30, 121MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  19% 849M/4.54G [00:11<00:31, 116MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  19% 870M/4.54G [00:15<03:21, 18.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  20% 902M/4.54G [00:15<02:08, 28.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  21% 933M/4.54G [00:15<01:27, 41.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  21% 965M/4.54G [00:15<01:03, 56.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  22% 986M/4.54G [00:15<00:52, 67.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  22% 1.01G/4.54G [00:16<00:44, 79.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  23% 1.03G/4.54G [00:16<00:37, 94.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  23% 1.06G/4.54G [00:16<00:29, 120MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  24% 1.09G/4.54G [00:16<00:24, 142MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  25% 1.12G/4.54G [00:16<00:21, 159MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  25% 1.14G/4.54G [00:16<00:20, 166MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  26% 1.16G/4.54G [00:16<00:20, 163MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  26% 1.18G/4.54G [00:17<00:20, 163MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  27% 1.21G/4.54G [00:17<00:19, 171MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  27% 1.23G/4.54G [00:17<00:21, 157MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  27% 1.25G/4.54G [00:21<03:28, 15.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  28% 1.28G/4.54G [00:21<02:13, 24.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.31G/4.54G [00:21<01:30, 35.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.34G/4.54G [00:22<01:05, 49.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.36G/4.54G [00:22<00:53, 59.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.38G/4.54G [00:22<00:43, 72.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.41G/4.54G [00:22<00:35, 87.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.43G/4.54G [00:22<00:30, 104MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.45G/4.54G [00:22<00:25, 120MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.48G/4.54G [00:22<00:20, 146MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.51G/4.54G [00:22<00:18, 162MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.53G/4.54G [00:22<00:18, 167MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.55G/4.54G [00:23<00:17, 174MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.58G/4.54G [00:23<00:15, 190MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.60G/4.54G [00:29<04:04, 12.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.63G/4.54G [00:29<03:01, 16.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.65G/4.54G [00:29<02:14, 21.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.67G/4.54G [00:30<01:39, 28.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.69G/4.54G [00:30<01:15, 38.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.71G/4.54G [00:30<00:57, 49.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.73G/4.54G [00:30<00:46, 60.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.75G/4.54G [00:30<00:38, 73.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.77G/4.54G [00:30<00:32, 85.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.79G/4.54G [00:30<00:27, 99.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.81G/4.54G [00:30<00:23, 116MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.84G/4.54G [00:31<00:20, 134MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.86G/4.54G [00:31<00:18, 142MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.88G/4.54G [00:31<00:18, 142MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.90G/4.54G [00:31<00:17, 147MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.92G/4.54G [00:31<00:16, 157MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.94G/4.54G [00:31<00:23, 111MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.96G/4.54G [00:32<00:20, 127MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.98G/4.54G [00:32<00:34, 74.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  44% 2.00G/4.54G [00:32<00:27, 91.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  45% 2.02G/4.54G [00:32<00:27, 91.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  45% 2.04G/4.54G [00:33<00:32, 76.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  45% 2.07G/4.54G [00:33<00:28, 88.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  46% 2.09G/4.54G [00:33<00:23, 105MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  46% 2.11G/4.54G [00:33<00:20, 120MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  47% 2.13G/4.54G [00:33<00:17, 135MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  48% 2.16G/4.54G [00:33<00:15, 158MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  48% 2.18G/4.54G [00:34<00:14, 165MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  48% 2.20G/4.54G [00:34<00:13, 172MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  49% 2.22G/4.54G [00:34<00:13, 173MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  50% 2.25G/4.54G [00:34<00:12, 187MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  50% 2.29G/4.54G [00:34<00:11, 198MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  51% 2.32G/4.54G [00:34<00:10, 204MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  52% 2.35G/4.54G [00:34<00:10, 209MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  52% 2.38G/4.54G [00:35<00:11, 194MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  53% 2.40G/4.54G [00:35<00:11, 189MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  53% 2.42G/4.54G [00:35<00:10, 194MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  54% 2.44G/4.54G [00:35<00:11, 187MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  54% 2.46G/4.54G [00:39<02:12, 15.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  55% 2.49G/4.54G [00:40<01:37, 21.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  55% 2.51G/4.54G [00:40<01:14, 27.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  56% 2.54G/4.54G [00:40<00:48, 41.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  56% 2.56G/4.54G [00:40<00:42, 46.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  57% 2.58G/4.54G [00:40<00:36, 54.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  57% 2.60G/4.54G [00:41<00:29, 66.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.62G/4.54G [00:41<00:23, 80.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.64G/4.54G [00:41<00:19, 98.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.67G/4.54G [00:41<00:15, 119MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.69G/4.54G [00:41<00:15, 122MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.73G/4.54G [00:41<00:12, 145MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.75G/4.54G [00:41<00:12, 144MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.77G/4.54G [00:42<00:16, 106MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.79G/4.54G [00:42<00:14, 119MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.81G/4.54G [00:42<00:13, 129MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.83G/4.54G [00:48<02:22, 12.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.86G/4.54G [00:48<01:29, 18.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.89G/4.54G [00:48<00:59, 27.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.93G/4.54G [00:48<00:41, 39.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.96G/4.54G [00:48<00:29, 53.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.98G/4.54G [00:48<00:24, 63.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  66% 3.00G/4.54G [00:48<00:20, 75.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  67% 3.02G/4.54G [00:49<00:16, 89.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  67% 3.04G/4.54G [00:49<00:14, 105MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  68% 3.07G/4.54G [00:49<00:11, 131MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  68% 3.10G/4.54G [00:49<00:09, 152MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  69% 3.14G/4.54G [00:49<00:08, 167MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  70% 3.16G/4.54G [00:49<00:08, 171MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  70% 3.18G/4.54G [00:49<00:07, 177MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  70% 3.20G/4.54G [00:49<00:07, 175MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  71% 3.23G/4.54G [00:50<00:07, 168MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  72% 3.25G/4.54G [00:52<00:37, 34.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  72% 3.27G/4.54G [00:52<00:28, 43.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  73% 3.30G/4.54G [00:52<00:19, 62.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  73% 3.33G/4.54G [00:52<00:14, 82.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  74% 3.37G/4.54G [00:52<00:11, 103MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  75% 3.39G/4.54G [00:52<00:09, 116MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  75% 3.41G/4.54G [00:52<00:08, 127MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  76% 3.43G/4.54G [00:53<00:07, 141MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  76% 3.45G/4.54G [00:53<00:07, 153MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  77% 3.48G/4.54G [00:53<00:06, 170MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  77% 3.50G/4.54G [00:53<00:05, 179MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  78% 3.53G/4.54G [00:53<00:05, 194MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  78% 3.55G/4.54G [00:53<00:05, 188MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  79% 3.58G/4.54G [00:53<00:05, 191MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  79% 3.60G/4.54G [00:53<00:05, 188MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  80% 3.63G/4.54G [00:54<00:04, 190MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  80% 3.65G/4.54G [01:00<01:14, 12.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  81% 3.68G/4.54G [01:00<00:47, 18.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  82% 3.71G/4.54G [01:00<00:31, 26.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  82% 3.73G/4.54G [01:00<00:24, 33.5MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  83% 3.75G/4.54G [01:00<00:18, 42.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  83% 3.77G/4.54G [01:01<00:14, 51.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  84% 3.80G/4.54G [01:01<00:11, 62.4MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  84% 3.82G/4.54G [01:01<00:09, 74.1MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  85% 3.84G/4.54G [01:01<00:08, 87.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  85% 3.86G/4.54G [01:01<00:06, 99.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  85% 3.88G/4.54G [01:01<00:06, 110MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.90G/4.54G [01:01<00:05, 116MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.92G/4.54G [01:02<00:05, 121MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.94G/4.54G [01:02<00:04, 127MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.96G/4.54G [01:02<00:04, 133MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.98G/4.54G [01:04<00:19, 28.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  88% 4.01G/4.54G [01:04<00:14, 37.0MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  89% 4.03G/4.54G [01:04<00:10, 47.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  89% 4.05G/4.54G [01:04<00:08, 59.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  90% 4.07G/4.54G [01:05<00:06, 72.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  90% 4.09G/4.54G [01:05<00:05, 85.2MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  91% 4.11G/4.54G [01:05<00:04, 96.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  91% 4.13G/4.54G [01:05<00:03, 105MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  91% 4.15G/4.54G [01:05<00:03, 113MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  92% 4.17G/4.54G [01:05<00:03, 120MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  92% 4.19G/4.54G [01:06<00:02, 125MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  93% 4.22G/4.54G [01:06<00:02, 128MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  93% 4.24G/4.54G [01:06<00:02, 130MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  94% 4.26G/4.54G [01:06<00:02, 133MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  94% 4.28G/4.54G [01:06<00:01, 137MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  95% 4.30G/4.54G [01:06<00:01, 134MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  95% 4.32G/4.54G [01:06<00:01, 129MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  96% 4.34G/4.54G [01:07<00:01, 123MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  96% 4.36G/4.54G [01:07<00:01, 121MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  97% 4.38G/4.54G [01:07<00:01, 124MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  97% 4.40G/4.54G [01:09<00:04, 28.9MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  97% 4.41G/4.54G [01:10<00:06, 20.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  98% 4.44G/4.54G [01:10<00:03, 29.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  98% 4.46G/4.54G [01:10<00:02, 39.7MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  99% 4.48G/4.54G [01:11<00:01, 51.6MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  99% 4.50G/4.54G [01:11<00:00, 63.8MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin: 100% 4.52G/4.54G [01:11<00:00, 64.3MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin: 100% 4.54G/4.54G [01:12<00:00, 62.8MB/s]\n",
            "Downloading shards: 100% 2/2 [03:04<00:00, 92.39s/it]\n",
            "Loading checkpoint shards:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 46, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 1075, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/launch.py\", line 681, in simple_launcher\n",
            "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '-m', 'autotrain.trainers.clm', '--training_config', 'mistral-7b-mj-finetuned/training_params.json']' died with <Signals.SIGKILL: 9>.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 21:47:10\u001b[0m | \u001b[36mautotrain.cli.run_llm\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mJob ID: 4758\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JvMRbVLEJlZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2467043e-31cd-4eea-82a2-fe2a8e7eea7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 2.2.2 which is incompatible.\n",
            "tensorflow 2.15.0 requires tensorboard<2.16,>=2.15, but you have tensorboard 2.16.2 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#@title 🤗 AutoTrain LLM\n",
        "#@markdown In order to use this colab\n",
        "#@markdown - upload train.csv to a folder named `data/`\n",
        "#@markdown - train.csv must contain a `text` column\n",
        "#@markdown - choose a project name if you wish\n",
        "#@markdown - change model if you wish, you can use most of the text-generation models from Hugging Face Hub\n",
        "#@markdown - add huggingface information (token) if you wish to push trained model to huggingface hub\n",
        "#@markdown - update hyperparameters if you wish\n",
        "#@markdown - click `Runtime > Run all` or run each cell individually\n",
        "#@markdown - report issues / feature requests here: https://github.com/huggingface/autotrain-advanced/issues\n",
        "\n",
        "import os\n",
        "!pip install -U autotrain-advanced > install_logs.txt\n",
        "!autotrain setup --colab > setup_logs.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2-_lkBS1WKA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "#@markdown Note: if you are using a restricted/private model, you need to enter your Hugging Face token in the next step.\n",
        "project_name = 'saiga-7b-lora-ner-v2' # @param {type:\"string\"}\n",
        "model_name = 'IlyaGusev/saiga_mistral_7b_merged' # @param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"ValterVar1\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "learning_rate = 2e-4 # @param {type:\"number\"}\n",
        "num_epochs = 5 #@param {type:\"number\"}\n",
        "batch_size = 8 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "block_size = 1024 # @param {type:\"number\"}\n",
        "trainer = \"sft\" # @param [\"default\", \"sft\", \"orpo\"] {type:\"raw\"}\n",
        "warmup_ratio = 0.1 # @param {type:\"number\"}\n",
        "weight_decay = 0.01 # @param {type:\"number\"}\n",
        "gradient_accumulation = 8 # @param {type:\"number\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"raw\"}\n",
        "peft = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "quantization = \"int4\" # @param [\"int4\", \"int8\", \"none\"] {type:\"raw\"}\n",
        "lora_r = 16 #@param {type:\"number\"}\n",
        "lora_alpha = 32 #@param {type:\"number\"}\n",
        "lora_dropout = 0.05 #@param {type:\"number\"}\n",
        "\n",
        "os.environ[\"PROJECT_NAME\"] = project_name\n",
        "os.environ[\"MODEL_NAME\"] = model_name\n",
        "os.environ[\"PUSH_TO_HUB\"] = str(push_to_hub)\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"LEARNING_RATE\"] = str(learning_rate)\n",
        "os.environ[\"NUM_EPOCHS\"] = str(num_epochs)\n",
        "os.environ[\"BATCH_SIZE\"] = str(batch_size)\n",
        "os.environ[\"BLOCK_SIZE\"] = str(block_size)\n",
        "os.environ[\"WARMUP_RATIO\"] = str(warmup_ratio)\n",
        "os.environ[\"WEIGHT_DECAY\"] = str(weight_decay)\n",
        "os.environ[\"GRADIENT_ACCUMULATION\"] = str(gradient_accumulation)\n",
        "os.environ[\"MIXED_PRECISION\"] = str(mixed_precision)\n",
        "os.environ[\"PEFT\"] = str(peft)\n",
        "os.environ[\"QUANTIZATION\"] = str(quantization)\n",
        "os.environ[\"LORA_R\"] = str(lora_r)\n",
        "os.environ[\"LORA_ALPHA\"] = str(lora_alpha)\n",
        "os.environ[\"LORA_DROPOUT\"] = str(lora_dropout)\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "os.environ[\"TRAINER\"] = trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "g3cd_ED_yXXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be3676a4-afc4-4742-dec8-407ed42e50bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 20:52:37\u001b[0m | \u001b[36mautotrain.cli.run_llm\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m344\u001b[0m - \u001b[1mRunning LLM\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-05-21 20:52:37\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m180\u001b[0m - \u001b[33m\u001b[1mParameters supplied but not used: config, version, train, func, inference, backend, deploy\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 20:52:37\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 20:52:37\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m360\u001b[0m - \u001b[1m['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'fp16', '-m', 'autotrain.trainers.clm', '--training_config', 'saiga-7b-lora-ner-v2/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 20:52:37\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m361\u001b[0m - \u001b[1m{'model': 'IlyaGusev/saiga_mistral_7b_merged', 'project_name': 'saiga-7b-lora-ner-v2', 'data_path': 'data/', 'train_split': 'train', 'valid_split': None, 'add_eos_token': False, 'block_size': 1024, 'model_max_length': 1024, 'padding': None, 'trainer': 'sft', 'use_flash_attention_2': False, 'log': 'none', 'disable_gradient_checkpointing': False, 'logging_steps': -1, 'evaluation_strategy': 'epoch', 'save_total_limit': 1, 'auto_find_batch_size': False, 'mixed_precision': 'fp16', 'lr': 0.0002, 'epochs': 5, 'batch_size': 8, 'warmup_ratio': 0.1, 'gradient_accumulation': 8, 'optimizer': 'adamw_torch', 'scheduler': 'linear', 'weight_decay': 0.01, 'max_grad_norm': 1.0, 'seed': 42, 'chat_template': None, 'quantization': 'int4', 'target_modules': 'all-linear', 'merge_adapter': False, 'peft': True, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.05, 'model_ref': None, 'dpo_beta': 0.1, 'max_prompt_length': 128, 'max_completion_length': None, 'prompt_text_column': 'prompt', 'text_column': 'text', 'rejected_text_column': 'rejected', 'push_to_hub': True, 'username': 'ValterVar1', 'token': '*****'}\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 5, in <module>\n",
            "    from accelerate.commands.accelerate_cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/accelerate_cli.py\", line 19, in <module>\n",
            "    from accelerate.commands.estimate import estimate_command_parser\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/commands/estimate.py\", line 34, in <module>\n",
            "    import timm\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/timm/__init__.py\", line 2, in <module>\n",
            "    from .layers import is_scriptable, is_exportable, set_scriptable, set_exportable\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/timm/layers/__init__.py\", line 7, in <module>\n",
            "    from .classifier import ClassifierHead, create_classifier, NormMlpClassifierHead\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/timm/layers/classifier.py\", line 15, in <module>\n",
            "    from .create_norm import get_norm_layer\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/timm/layers/create_norm.py\", line 14, in <module>\n",
            "    from torchvision.ops.misc import FrozenBatchNorm2d\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py\", line 6, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/_meta_registrations.py\", line 164, in <module>\n",
            "    def meta_nms(dets, scores, iou_threshold):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/library.py\", line 440, in inner\n",
            "    handle = entry.abstract_impl.register(func_to_register, source)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_library/abstract_impl.py\", line 30, in register\n",
            "    if torch._C._dispatch_has_kernel_for_dispatch_key(self.qualname, \"Meta\"):\n",
            "RuntimeError: operator torchvision::nms does not exist\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-05-21 20:52:41\u001b[0m | \u001b[36mautotrain.cli.run_llm\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m350\u001b[0m - \u001b[1mJob ID: 2432\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!autotrain llm \\\n",
        "--train \\\n",
        "--model ${MODEL_NAME} \\\n",
        "--project-name ${PROJECT_NAME} \\\n",
        "--data-path data/ \\\n",
        "--text-column text \\\n",
        "--lr ${LEARNING_RATE} \\\n",
        "--batch-size ${BATCH_SIZE} \\\n",
        "--epochs ${NUM_EPOCHS} \\\n",
        "--block-size ${BLOCK_SIZE} \\\n",
        "--warmup-ratio ${WARMUP_RATIO} \\\n",
        "--lora-r ${LORA_R} \\\n",
        "--lora-alpha ${LORA_ALPHA} \\\n",
        "--lora-dropout ${LORA_DROPOUT} \\\n",
        "--weight-decay ${WEIGHT_DECAY} \\\n",
        "--gradient-accumulation ${GRADIENT_ACCUMULATION} \\\n",
        "--quantization ${QUANTIZATION} \\\n",
        "--mixed-precision ${MIXED_PRECISION} \\\n",
        "--username ${HF_USERNAME} \\\n",
        "--trainer ${TRAINER} \\\n",
        "$( [[ \"$PEFT\" == \"True\" ]] && echo \"--peft\" ) \\\n",
        "$( [[ \"$PUSH_TO_HUB\" == \"True\" ]] && echo \"--push-to-hub --token ${HF_TOKEN}\" )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n7cWOZs1c8Gz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}